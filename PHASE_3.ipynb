{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression\n",
    "You have previously learned about simple linear regression models. In these models, what you try to do is fit a linear relationship between two variables. Let's refresh our memory with the example below. Here, we are trying to find a relationship between seniority and monthly income. The monthly income is shown in units of $1000 USD.\n",
    "\n",
    "y = data[\"mpg\"]\n",
    "X_baseline = data[[\"weight\"]]\n",
    "baseline_model = sm.OLS(y, sm.add_constant(X_baseline))\n",
    "baseline_results = baseline_model.fit()\n",
    "\n",
    "print(baseline_results.summary())\n",
    "\n",
    "The regression line:\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "data.plot.scatter(x=\"weight\", y=\"mpg\", label=\"Data points\", ax=ax)\n",
    "sm.graphics.abline_plot(model_results=baseline_results, label=\"Regression line\", ax=ax, color=\"black\")\n",
    "ax.legend();\n",
    "\n",
    "And the residuals:\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(data[\"mpg\"], baseline_results.resid)\n",
    "ax.axhline(y=0, color=\"black\")\n",
    "ax.set_xlabel(\"weight\")\n",
    "ax.set_ylabel(\"residuals\");\n",
    "\n",
    "From our simple linear regression to a multiple linear regression. The process of building this model with StatsModels is very similar to the process of building our baseline simple regression model; this time we simply create an X variable containing multiple columns.\n",
    "\n",
    "X_second = data[[\"weight\", \"model year\"]]\n",
    "X_second\n",
    "\n",
    "second_model = sm.OLS(y, sm.add_constant(X_second))\n",
    "second_results = second_model.fit()\n",
    "\n",
    "print(second_results.summary())\n",
    "\n",
    "Model Fit\n",
    "sm.graphics.plot_fit(second_results, \"weight\")\n",
    "plt.show()\n",
    "We can also plot the fit for the other predictor, model year:\n",
    "\n",
    "sm.graphics.plot_fit(second_results, \"model year\")\n",
    "plt.show()\n",
    "\n",
    "Partial Regression Plot\n",
    "Then, instead of a basic scatter plot with a best-fit line (since our model is now higher-dimensional), we'll use two partial regression plots, one for each of our predictors.\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "sm.graphics.plot_partregress_grid(second_results, exog_idx=[\"weight\", \"model year\"], fig=fig)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "Plotting Residuals\n",
    "One approach to plotting residuals from a multiple regression model is to use the same approach as in simple regression, just plotting the value of the predictor on the x-axis vs. the model residuals on the y-axis.\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(15,5), sharey=True)\n",
    "\n",
    "weight_ax = axes[0]\n",
    "weight_ax.scatter(data[\"weight\"], second_results.resid)\n",
    "weight_ax.axhline(y=0, color=\"black\")\n",
    "weight_ax.set_xlabel(\"weight\")\n",
    "weight_ax.set_ylabel(\"residuals\")\n",
    "\n",
    "year_ax = axes[1]\n",
    "year_ax.scatter(data[\"model year\"], second_results.resid)\n",
    "year_ax.axhline(y=0, color=\"black\")\n",
    "year_ax.set_xlabel(\"model year\");\n",
    "\n",
    "Plotting All Four at Once\n",
    "If you are interested in creating all of these plots at once for a given predictor, StatsModels has a wrapper that can do this also:\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "sm.graphics.plot_regress_exog(second_results, \"weight\", fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Using scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "sklearn_third_model = LinearRegression()\n",
    "sklearn_third_model.fit(X_all, y)\n",
    "\n",
    "print(f\"\"\"\n",
    "StatsModels R-Squared:    {third_results.rsquared}\n",
    "scikit-learn R-Squared:   {sklearn_third_model.score(X_all, y)}\n",
    "\n",
    "StatsModels intercept:     {third_results.params[\"const\"]}\n",
    "scikit-learn intercept:    {sklearn_third_model.intercept_}\n",
    "\n",
    "StatsModels coefficients:  {third_results.params[1:].values}\n",
    "scikit-learn coefficients: {sklearn_third_model.coef_}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Regression Model Evaluation\n",
    "Multiple regression models, like simple regression models, can be evaluated using R-Squared (coefficient of determination) for measuring the amount of explained variance, and the F-statistic for determining statistical significance. You also may want to consider using other metrics, including adjusted R-Squared and error-based metrics such as MAE and RMSE\n",
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "data = pd.read_csv(\"auto-mpg.csv\")\n",
    "data\n",
    "y = data[\"mpg\"]\n",
    "X = data[[\"weight\", \"model year\"]]\n",
    "model = sm.OLS(y, sm.add_constant(X))\n",
    "results = model.fit()\n",
    "results.fvalue, results.f_pvalue\n",
    "*very small p-value, we can say that the model is statistically significant.*\n",
    "results.rsquared\n",
    "*This means that our model is explaining about 81% of the variance in mpg.*\n",
    "\n",
    "Some limitations of R-Squared include : First, as we add more predictors, R-Squared is only going to increase. Second, \"proportion of variance explained\" may not be the best way to describe your model's performance. These drawbacks are addressed by adjusted R-Squared\n",
    "\n",
    "results.rsquared_adj\n",
    "\n",
    "Some issues with R-Squared can't be addressed with small tweaks like adjusted R-Squared. While R-Squared is a relative metric that compares the variance explained by the model to the variance explained by an intercept-only \"baseline\" model, most error-based metrics are absolute metrics that describe some form of average error.\n",
    "\n",
    "## Mean Absolute Error\n",
    "Mean absolute error (MAE) calculates the absolute value of each error before adding it to the sum. We can just use the .abs() method on the residuals series to do this:\n",
    "results.resid.abs()\n",
    "mae = results.resid.abs().sum() / len(y)\n",
    "mae\n",
    "*a lower MAE is better, and the smallest theoretically possible MAE is 0.*\n",
    "\n",
    "## Root Mean Squared Error\n",
    "Another popular error-based metric is root mean squared error. Root mean squared error (RMSE) calculates the squared value of each error, sums them, then takes the square root at the end.\n",
    "results.resid ** 2\n",
    "rmse = ((results.resid ** 2).sum() / len(y)) ** 0.5\n",
    "rmse\n",
    "\n",
    "# Calculating Metrics with Scikit-Learn\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "mean_absolute_error(y, y_pred)\n",
    "mean_squared_error(y, y_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Categorical Variables\n",
    "Engineer a new feature, make, using the car name feature:\n",
    "\n",
    "data[\"make\"] = data[\"car name\"].str.split().apply(lambda x: x[0])\n",
    "data\n",
    "\n",
    "data[[\"make\", \"origin\"]].groupby(\"make\").first().sort_values(\"origin\")\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,5))\n",
    "\n",
    "data.plot.scatter(x=\"origin\", y=\"mpg\", ax=ax1)\n",
    "data.groupby(\"origin\").mean('mpg').plot.bar(y='mpg', ax=ax2);\n",
    "\n",
    " A continuous variable is essentially always numeric, and a string variable is essentially always categorical.\n",
    "\n",
    "## Transforming Categorical Variables with One-Hot Encoding\n",
    "You can use the get_dummies function from pandas.\n",
    "\n",
    "origin_df = data[[\"origin\"]].copy()\n",
    "origin_df.sample(10, random_state=1)\n",
    "\n",
    "We can also do one-hot encoding on the entire DataFrame at once, just specifying the columns we consider to be categorical:\n",
    "\n",
    "pd.get_dummies(data, columns=[\"origin\", \"make\"], dtype=int\n",
    "\n",
    "## Multiple Regression with One-Hot Encoded Variables\n",
    "Let's go ahead and create a linear regression model with weight, model year, and origin.\n",
    "\n",
    "y = data[\"mpg\"]\n",
    "X = data[[\"weight\", \"model year\", \"origin\"]]\n",
    "X\n",
    "X = pd.get_dummies(X, columns=[\"origin\"], drop_first=True, dtype=int)\n",
    "X\n",
    "import statsmodels.api as sm\n",
    "\n",
    "model = sm.OLS(y, sm.add_constant(X))\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())\n",
    "\n",
    "## One-Hot Encoding with Scikit-Learn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(drop=\"first\", sparse_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we typically use StatsModels to build multiple regression models, just like we did for simple regression models\n",
    "Another library that can be used for linear regression is scikit-learn. This is mostly relevant for predictive modeling (machine learning) because it doesn't calculate p-values for coefficients\n",
    "There are some problems with R-Squared (coefficient of determination) for evaluating multiple regression models\n",
    "R-Squared will only ever increase as we add more features. Adjusted R-Squared accounts for the number of features and is a better metric for multiple regression\n",
    "Proportion of variance explained is not intuitive for stakeholders. Error-based metrics such as mean absolute error (MAE) and root mean squared error (RMSE) are helpful tools to express how incorrect the model is in an average prediction\n",
    "Now that we have the ability to use multiple features in our regression models, we can use categorical features\n",
    "Categorical features must be preprocessed before they can be used in linear regression models\n",
    "Specifically we used one-hot encoding to create dummy variables (1s or 0s) representing each category\n",
    "In order to avoid the dummy variable trap we need to drop one of the dummy variable columns. Whichever column is dropped becomes the reference category, where all other category coefficients are compared to this category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
